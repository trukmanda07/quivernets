<!--
  Slide 22: Finale: Comparison
  Time: 64:00-68:00
-->
<div class="space-y-0.5">
  <h4 class="text-sm font-bold text-center">Two Ways to Solve Linear Regression</h4>
  <div class="grid grid-cols-2 gap-0.5">
    <div class="bg-blue-100 p-1 rounded-lg border-3 border-blue-500">
      <h5 class="text-3xl font-bold mb-0">Normal Equation</h5>
      <div class="bg-white p-1 rounded shadow">
        <p class="font-mono text-2xl text-center mb-0">$W = (X^TX)^{-1}X^Ty$</p>
        <p class="text-2xl mt-0.5 mb-0 leading-tight"><strong>Pros:</strong><br>✓ Direct solution<br>✓ No
          hyperparameters<br>✓ Exact answer</p>
        <p class="text-2xl mt-0.5 mb-0 leading-tight"><strong>Cons:</strong><br>✗ $O(n^3)$ complexity<br>✗ Doesn't
          scale<br>✗ Memory intensive</p>
        <p class="text-2xl mt-0.5 mb-0"><strong>Best for:</strong></p>
        <p class="text-2xl leading-tight bg-blue-50 p-0.5 rounded">Small datasets (< 10k obs)</p>
      </div>
    </div>
    <div class="bg-green-100 p-1 rounded-lg border-3 border-green-500">
      <h5 class="text-3xl font-bold mb-0">Gradient Descent ⭐</h5>
      <div class="bg-white p-1 rounded shadow">
        <p class="font-mono text-2xl text-center mb-0">Iterative updates</p>
        <p class="text-2xl mt-0.5 mb-0 leading-tight"><strong>Pros:</strong><br>✓ Scales to huge data<br>✓ Low
          memory<br>✓ Generalizes to non-linear</p>
        <p class="text-2xl mt-0.5 mb-0 leading-tight"><strong>Cons:</strong><br>✗ Needs tuning<br>✗ Approximate
          solution<br>✗ Takes iterations</p>
        <p class="text-2xl mt-0.5 mb-0"><strong>Best for:</strong></p>
        <p class="text-2xl leading-tight bg-green-50 p-0.5 rounded">Large datasets, deep learning</p>
      </div>
    </div>
  </div>
</div>