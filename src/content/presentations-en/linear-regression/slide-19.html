<!--
  Slide 19: Derivation Step 3: Solve
  Time: 55:00-58:00
-->
<div class="space-y-1.5">
  <h4 class="text-sm font-bold text-center">Solving for Optimal $W$</h4>
  <div class="bg-white p-2.5 rounded-lg shadow-lg border-4 border-blue-500">
    <h5 class="text-3xl font-bold mb-1">Set Gradient to Zero</h5>
    <div class="bg-blue-50 p-2 rounded text-center space-y-1">
      <p class="font-mono text-2xl">$\nabla f(W) = -2X^Ty + 2X^TXW = 0$</p>
      <p class="text-2xl">↓ Divide by 2</p>
      <p class="font-mono text-2xl">$-X^Ty + X^TXW = 0$</p>
      <p class="text-2xl">↓ Add $X^Ty$ to both sides</p>
      <p class="font-mono text-2xl">$X^TXW = X^Ty$</p>
    </div>
  </div>
  <div class="bg-gradient-to-r from-green-100 to-emerald-100 p-3 rounded-lg border-4 border-green-500">
    <h5 class="text-3xl font-bold mb-1">The Normal Equation ⭐</h5>
    <div class="bg-white p-2 rounded-lg shadow-lg text-center">
      <p class="font-mono text-2xl mb-1">$W = (X^TX)^{-1}X^Ty$</p>
      <p class="text-2xl font-bold text-green-700">Closed-form solution for linear regression!</p>
    </div>
  </div>
</div>