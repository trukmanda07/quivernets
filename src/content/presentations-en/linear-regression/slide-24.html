<!--
  Slide 24: What's Next?
  Time: 73:00-75:00
-->
<div class="flex items-center justify-center h-full">
  <div
    class="bg-gradient-to-br from-purple-100 to-pink-100 p-6 rounded-lg border-4 border-purple-500 max-w-3xl text-center">
    <h5 class="text-3xl font-bold mb-2 text-purple-700">Coming Up Next: Gradient Descent!</h5>
    <p class="text-2xl mb-2 leading-relaxed">Now that we understand linear regression, we need to learn how to
      <strong>actually solve it</strong> for large datasets.</p>
    <div class="bg-white p-3 rounded-lg shadow-lg">
      <p class="text-2xl mb-1.5">üîç We'll explore:</p>
      <ul class="list-disc ml-8 text-left space-y-0.5 text-2xl leading-tight">
        <li>How gradient descent takes steps toward the minimum</li>
        <li>Learning rates and convergence</li>
        <li>Batch vs. stochastic gradient descent</li>
        <li>Why it's the backbone of deep learning</li>
      </ul>
    </div>
    <div class="mt-2 bg-gradient-to-r from-green-500 to-emerald-500 text-white p-2.5 rounded-lg">
      <p class="text-2xl italic">"The journey from theory to practice begins with optimization!"</p>
      <p class="text-2xl mt-1">- QuiverLearn</p>
    </div>
  </div>
</div>