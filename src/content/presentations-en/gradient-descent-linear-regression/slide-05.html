<!--
  Slide 5: Question 2 - Computing Gradients (Single Variable)
  Time: 12:00-16:00
-->
<div class="space-y-1">
  <h4 class="text-sm font-bold">Computing Gradients: Single Variable</h4>
  <div class="bg-gradient-to-br from-purple-50 to-pink-50 p-2 rounded-lg border-4 border-purple-500">
    <h5 class="text-3xl font-bold mb-0">Derivative (One Variable)</h5>
    <div class="bg-white p-1.5 rounded-lg shadow-lg">
      <p class="text-2xl mb-0">The derivative $f'(x)$ represents the slope of $f(x)$ at point $x$.</p>
      <p class="text-2xl mt-1 mb-0 font-semibold">For linear regression with one variable:</p>
      <div class="bg-gray-100 p-1.5 rounded-lg mt-1">
        <p class="text-2xl font-mono">$f(w) = \sum_{i=1}^m (y_i - (w_0 + w_1x_i))^2$</p>
      </div>
      <p class="text-2xl mt-1">We compute derivatives with respect to each weight:</p>
      <p class="text-2xl font-mono text-center mt-0.5">$\frac{\partial f}{\partial w_0}$ and $\frac{\partial
        f}{\partial w_1}$</p>
    </div>
  </div>
  <div class="bg-blue-100 p-1.5 rounded-lg border-l-4 border-blue-500">
    <p class="text-2xl font-bold mb-0">ðŸŽ¯ Simple Case:</p>
    <p class="text-2xl">One variable = one derivative = slope at that point!</p>
  </div>
</div>