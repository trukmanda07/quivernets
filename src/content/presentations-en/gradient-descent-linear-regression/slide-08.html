<!--
  Slide 8: Question 3 - Why Gradients? Convex Functions
  Time: 24:00-28:00
-->
<div class="space-y-1">
  <h4 class="text-sm font-bold">Why Use Gradients for Optimization?</h4>
  <div class="bg-gradient-to-br from-green-50 to-emerald-50 p-2 rounded-lg border-4 border-green-500">
    <h5 class="text-3xl font-bold mb-0">Convex Functions: One Global Minimum</h5>
    <div class="bg-white p-1.5 rounded-lg shadow-lg">
      <p class="text-2xl mb-1">Our linear regression metric $f(W) = \|y - XW\|_2^2$ is <span
          class="font-bold text-green-700">convex</span>.</p>
      <p class="text-2xl font-bold mb-0.5">Special Property:</p>
      <p class="text-2xl leading-tight">✓ Only ONE minimum—the global minimum<br>✓ No local minima to get stuck in<br>✓
        Any minimum we find is the BEST solution<br>✓ Local minimum = Global minimum</p>
    </div>
  </div>
  <div class="grid grid-cols-2 gap-1 mt-1">
    <div class="bg-green-100 p-1.5 rounded-lg border-2 border-green-500">
      <p class="text-2xl font-bold mb-0">✓ Linear Regression</p>
      <p class="text-2xl leading-tight">Bowl-shaped surface<br>Single minimum<br>Always converges</p>
    </div>
    <div class="bg-red-100 p-1.5 rounded-lg border-2 border-red-500">
      <p class="text-2xl font-bold mb-0">✗ Neural Networks</p>
      <p class="text-2xl leading-tight">Multiple local minima<br>May get stuck<br>No guarantee</p>
    </div>
  </div>
</div>