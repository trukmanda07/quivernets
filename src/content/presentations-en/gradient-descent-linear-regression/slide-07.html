<!--
  Slide 7: Question 2 - Gradient Vector
  Time: 20:00-24:00
-->
<div class="space-y-1">
  <h4 class="text-sm font-bold">The Gradient Vector</h4>
  <div class="bg-gradient-to-br from-indigo-50 to-purple-50 p-2 rounded-lg border-4 border-indigo-500">
    <h5 class="text-3xl font-bold mb-0">Gradient Generalizes Derivatives</h5>
    <div class="bg-white p-1.5 rounded-lg shadow-lg">
      <p class="text-2xl mb-1">The <span class="font-bold text-indigo-700">gradient</span> is a <span
          class="font-bold">vector</span> containing all partial derivatives:</p>
      <div class="bg-gray-100 p-1.5 rounded-lg text-center">
        <p class="text-2xl font-mono">$\nabla_\mathbf{x}f(\mathbf{x}) = \begin{bmatrix} \frac{\partial
          f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n}
          \end{bmatrix}$</p>
      </div>
      <p class="text-2xl mt-1">The $i$-th element is the partial derivative with respect to $x_i$.</p>
    </div>
  </div>
  <div class="bg-yellow-100 border-l-4 border-yellow-500 p-1.5">
    <p class="text-2xl font-bold mb-0">ðŸ’¡ Critical Point Property</p>
    <p class="text-2xl">At a minimum (or maximum), all partial derivatives equal
      zero:<br>$\nabla_\mathbf{x}f(\mathbf{x}) = \mathbf{0}$</p>
    <p class="text-2xl mt-1 font-bold text-yellow-700">This is how we found the normal equation!</p>
  </div>
</div>